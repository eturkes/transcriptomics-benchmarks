---
title: "03 Normalization"
author:
  - name: "Emir Turkes [emir.turkes@eturkes.com]"
  - name: "UK Dementia Research Institute at UCL"
date: '`r strftime(Sys.time(), format = "%B %d, %Y")`'
bibliography: "../../transcriptomics-benchmarks.bib"
biblio-style: apalike
link-citations: true
output:
  html_document:
    number_sections: true
    theme: lumen
    highlight: haddock
    toc: true
    toc_depth: 2
    toc_float:
      collapsed: false
      smooth_scroll: false
knit:
  (function(inputFile, encoding) {
    rmarkdown::render(
      inputFile, encoding = encoding,
      output_file = "../../results/habib-2017-snRNAseq/03-normalization.html")})
---

```{r, include = FALSE}
#    This file is part of transcriptomics-benchmarks.
#    Copyright (C) 2019  Emir Turkes
#
#    This program is free software: you can redistribute it and/or modify
#    it under the terms of the GNU General Public License as published by
#    the Free Software Foundation, either version 3 of the License, or
#    (at your option) any later version.
#
#    This program is distributed in the hope that it will be useful,
#    but WITHOUT ANY WARRANTY; without even the implied warranty of
#    MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
#    GNU General Public License for more details.
#
#    You should have received a copy of the GNU General Public License
#    along with this program.  If not, see <http://www.gnu.org/licenses/>.
#
#    Emir Turkes can be contacted at emir.turkes@eturkes.com

knitr::opts_chunk$set(fig.width = 8.5, fig.height = 7)
```

<style type="text/css">
body {font-size: 16px;}
h1.title {font-size: 35px;}
h1 {font-size: 24px;}
h2 {font-size: 22px;}
h3 {font-size: 20px;}
.toc-content {padding-left: 0px; padding-right: 0px;}
div.tocify {width: 100%;}
.tocify-subheader .tocify-item {font-size: 0.95em; padding-left: 25px; text-indent: 0;}
.tocify-subheader .tocify-subheader .tocify-item {
  font-size: 0.90em; padding-left: 35px; text-indent: 0;}
div.main-container {max-width: none; width: 100%;}
</style>

*This file is a part of the [Transcriptomics Benchmarks Project](https://github.com/eturkes/transcriptomics-benchmarks).*

```{r}
assets_dir <- file.path(getwd(), "..", "..", "assets/habib-2017-snRNAseq")
results_dir <- file.path(getwd(), "..", "..", "results/habib-2017-snRNAseq")

packages <- c(
  "conflicted", "SingleCellExperiment", "magrittr", "dplyr", "ggplot2", "ggrepel", "S4Vectors",
  "SummarizedExperiment", "DropletUtils", "scran", "BiocSingular", "scater", "Rtsne", "svd",
  "SC3", "DT", "data.table", "Seurat", "uwot", "viridis", "rsvd", "future")
invisible(suppressPackageStartupMessages(lapply(packages, library, character.only = TRUE)))

conflict_prefer("which", "BiocGenerics")
options(stringsAsFactors = FALSE)
plan("multiprocess")

# Create a unique cache and results data directory for each iterated section.
if (!dir.exists(file.path(assets_dir, "cache", "03"))) {
  dir.create(file.path(assets_dir, "cache", "03"), recursive = TRUE)}
if (!dir.exists(file.path(results_dir, "data", "03"))) {
  dir.create(file.path(results_dir, "data", "03"), recursive = TRUE)}

# ggplot2 function providing custom aesthetics and automatic placement of categorical labels.
# For continuous data, a colorbar is implemented.
dim_red_plot <- function(data, x, y, col, type) {
  gg <- ggplot(data, aes_string(x = x, y = y, color = col)) +
    geom_point(alpha = 0.35, stroke = 0.05, shape = 21, aes_string(fill = col)) +
    theme_classic() +
    theme(
      legend.position = "right", plot.title = element_text(hjust = 0.5),
      legend.title = element_blank()) +
    guides(color = guide_legend(override.aes = list(alpha = 1)))
    if (type == "cat") {
      gg <- gg + geom_label_repel(data = label_df2, aes(label = label), show.legend = FALSE)
    } else if (type == "cont") {
      gg <- ggplot(data, aes_string(x = x, y = y)) +
        geom_point(alpha = 0.35, stroke = 0.05, aes_string(color = col)) +
        theme_classic() +
        theme(
          legend.position = "right", plot.title = element_text(hjust = 0.5),
          legend.title = element_blank()) +
        scale_colour_viridis()}
  gg}

# Adds download buttons.
datatable_custom <- function(dt) {
  datatable(
    dt,
    extensions = "Buttons", options = list(dom = "Blfrtip", buttons = list(
      "copy", "print",
      list(extend = "collection", buttons = c("csv", "excel", "pdf"), text = "Download"))))}
```

We use the SCE object from the previous analysis, `02_qc.Rmd`.

```{r}
sce <- readRDS(file.path(results_dir, "data", "02", "sce.rds"))
sce
```

# Library Size Normalization

We first try the simplest scaling normalization strategy.

```{r}
lib_sf <- librarySizeFactors(sce)
summary(lib_sf)
hist(log10(lib_sf), xlab = "log10(size factor)", col = "grey80")
```

# Normalization by Deconvolution

A deconvolution approach attempts to address the possibility of unbalanced differential expression between samples, which may be more applicable for scRNAseq analysis.

```{r, cache = TRUE}
rds <- file.path(assets_dir, "cache", "03", "deconv_norm.rds")
if (file.exists(rds)) {
  sce <- readRDS(rds)
} else {
  set.seed(1)
  clusters <- quickCluster(sce, BPPARAM = MulticoreParam())
  sce <- computeSumFactors(sce, cluster = clusters, min.mean = 0.1, BPPARAM = MulticoreParam())
  sce <- logNormCounts(sce)
  sce <- runPCA(sce, BPPARAM = MulticoreParam())
  rm(clusters)
  saveRDS(sce, rds)}
```

```{r}
plotPCA(sce, colour_by = "cell_id_stem")
```

# Scaling

We create an assay with additional scaling applied.

```{r}
# Caching turned off due to error:
# Error in lazyLoadDBinsertVariable(vars[i], from, datafile, ascii, compress,  :
# long vectors not supported yet: connections.c:5984
rds <- file.path(assets_dir, "cache", "03", "scalecounts.rds")
if (file.exists(rds)) {
  sce <- readRDS(rds)
} else {
  assay(sce, "scalecounts") <- t(scale(t((logcounts(sce)))))
  saveRDS(sce, rds)}
```

# Seurat

We also try Seurat's default approach.

```{r}
# Caching turned off due to error:
# Error in lazyLoadDBinsertVariable(vars[i], from, datafile, ascii, compress,  :
# long vectors not supported yet: connections.c:5984
rds <- file.path(assets_dir, "cache", "03", "seurat.rds")
if (file.exists(rds)) {
  seurat <- readRDS(rds)
} else {
  seurat <- as.Seurat(sce)
  seurat <- NormalizeData(seurat)
  seurat <- ScaleData(seurat, features = rownames(seurat))
  seurat <- RunPCA(seurat, features = rownames(seurat))
  saveRDS(seurat, rds)}
```

```{r}
PCAPlot(seurat, group.by = "cell_id_stem")
```

# sctransform

Using the wrapper within Seurat.
Note that the PCA is performed on HVGs returned from the `SCTransform` function.
While using residuals from all the genes are preferable at this stage of benchmarking, memory limits were exceeded, even on a 32GB machine.

```{r}
# Caching turned off due to error:
# Error in lazyLoadDBinsertVariable(vars[i], from, datafile, ascii, compress,  :
# long vectors not supported yet: connections.c:5984
rds <- file.path(assets_dir, "cache", "03", "sctrans.rds")
if (file.exists(rds)) {
  seurat_sct <- readRDS(rds)
} else {
  sce_anno <- readRDS(file.path(results_dir, "data", "02", "sce_anno.rds"))
  seurat_sct <- as.Seurat(sce_anno, data = NULL)
  seurat_sct <- SCTransform(seurat_sct, vars.to.regress = "subsets_Mito_percent", verbose = FALSE)
  seurat_sct <- RunPCA(seurat_sct)
  saveRDS(seurat_sct, rds)}
```

```{r}
PCAPlot(seurat_sct, group.by = "cell_id_stem")
```

# Testing

We view the contents of our various normalization methods.

## SCE

```{r}
counts(sce)["SST", names(which(counts(sce)["SST", ] > 0)[1])]
logcounts(sce)["SST", names(which(counts(sce)["SST", ] > 0)[1])]
assay(sce, "scalecounts")["SST", names(which(counts(sce)["SST", ] > 0)[1])]

counts(sce)["MALAT1", names(which(counts(sce)["SST", ] > 0)[1])]
logcounts(sce)["MALAT1", names(which(counts(sce)["SST", ] > 0)[1])]
assay(sce, "scalecounts")["MALAT1", names(which(counts(sce)["SST", ] > 0)[1])]
```

## Seurat

```{r}
GetAssayData(seurat, slot = "counts")["SST", names(which(counts(sce)["SST", ] > 0)[1])]
GetAssayData(seurat, slot = "data")["SST", names(which(counts(sce)["SST", ] > 0)[1])]
GetAssayData(seurat, slot = "scale.data")["SST", names(which(counts(sce)["SST", ] > 0)[1])]

GetAssayData(seurat, slot = "counts")["MALAT1", names(which(counts(sce)["SST", ] > 0)[1])]
GetAssayData(seurat, slot = "data")["MALAT1", names(which(counts(sce)["SST", ] > 0)[1])]
GetAssayData(seurat, slot = "scale.data")["MALAT1", names(which(counts(sce)["SST", ] > 0)[1])]
```

## sctransform

```{r}
GetAssayData(seurat_sct, slot = "counts")["SST", names(which(counts(sce)["SST", ] > 0)[1])]
GetAssayData(seurat_sct, slot = "data")["SST", names(which(counts(sce)["SST", ] > 0)[1])]
GetAssayData(seurat_sct, slot = "scale.data")["SST", names(which(counts(sce)["SST", ] > 0)[1])]

GetAssayData(seurat_sct, slot = "counts")["MALAT1", names(which(counts(sce)["SST", ] > 0)[1])]
GetAssayData(seurat_sct, slot = "data")["MALAT1", names(which(counts(sce)["SST", ] > 0)[1])]
GetAssayData(seurat_sct, slot = "scale.data")["SST", names(which(counts(sce)["SST", ] > 0)[1])]
```

# References

This is the concluding section of the document. Here we write relevant results to disk, output the sessionInfo, and create a bibliography for works cited.

```{r}
saveRDS(sce, file.path(results_dir, "data", "03", "sce.rds"))
saveRDS(seurat, file.path(results_dir, "data", "03", "seurat.rds"))
saveRDS(seurat_sct, file.path(results_dir, "data", "03", "seurat_sct.rds"))

sessionInfo()
```
